# This configuration file follows the INI File Structure
# https://docs.python.org/3/library/configparser.html#supported-ini-file-structure

[DATA]
# Alternatives include en_core_web_sm, en_core_web_lg, etc.
Spacy NLP Model = en_core_web_lg
Spacy Vocab Dir = ex_data/vocab
Spacy KB = ex_data/kb
Conll Annotated = ex_data/conll/conll-wikidata-iob-annotations
Wikipedia Abstracts = ex_data/yi-chun/wikidata-wikipedia.tsv
Candidate Info = data/docs_entities_info.json

[INPUT VECTORS]
Read Input Vectors From Dir = False
Use Balanced Dataset = False
# Full dataset instructions:
Input Vectors Dir = data/vectors
Input IDs = data_vectors_input_ids.pt
Attention Mask = data_vectors_attention_mask.pt
Token Type IDs = data_vectors_token_type_ids.pt
Labels = data_vectors_labels.pt
# Balanced dataset instructions:
Balanced Dataset Dir = data/balanced_dataset
N Negative Samples = 1

[BERT]
# Name of the model if fetched from Huggingface:
Model ID = bert-base-uncased
Max Sequence Length = 512
Bert Model Dir = models/0_bert-base-uncased
Save Model Dir = models/trained

[TRAINING]
Epochs = 3
Freeze N Transformers = 8
Batch Size = 24
Use Default Split = True
# If Use Default Split = False:
Training Set Size = 0.8
Validation Set Size = 0.1
Test Set Size = 0.1

[VERBOSITY]
Training Update Frequency = 100
Validation Update Frequency = 50
Test Update Frequency = 50
